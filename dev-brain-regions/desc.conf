title = "An atlas of cortical arealization identifies dynamic molecular signatures"

# a thumbnail image of some nice image representing your dataset, sometimes it's figure 1, sometimes 
# the journal cover, or just a screenshot of the t-SNE plot. If the file is bigger than 400px,
# optimize the image size to something smaller that can load progressively with this Unix command:
# convert myImage.png -sampling-factor 4:2:0 -strip -quality 85 -interlace JPEG -colorspace sRGB -resize 400^ thumb.jpg

#image = "thumb.jpg"

# abstract of paper or dataset summary text
abstract = """
The human brain is subdivided into distinct anatomical structures, including
the neocortex, which in turn encompasses dozens of distinct specialized
cortical areas. Early morphogenetic gradients are known to establish early
brain regions and cortical areas, but how early patterns result in finer and
more discrete spatial differences remains poorly understood1. Here we use
single-cell RNA sequencing to profile ten major brain structures and six
neocortical areas during peak neurogenesis and early gliogenesis. Within the
neocortex, we find that early in the second trimester, a large number of genes
are differentially expressed across distinct cortical areas in all cell types,
including radial glia, the neural progenitors of the cortex. However, the
abundance of areal transcriptomic signatures increases as radial glia
differentiate into intermediate progenitor cells and ultimately give rise to
excitatory neurons. Using an automated, multiplexed single-molecule fluorescent
in situ hybridization approach, we find that laminar gene-expression patterns
are highly dynamic across cortical regions. Together, our data suggest that
early cortical areal patterning is defined by strong, mutually exclusive
frontal and occipital gene-expression signatures, with resulting gradients
giving rise to the specification of areas between these two poles throughout
successive developmental timepoints.
"""

# methods: please describe roughly what the samples are and how you processed them computationally
methods = """
<section>Sample acquisition</section>
<p>
De-identified tissue samples were collected with previous consent in strict
observance of the legal and institutional ethical regulations. Protocols were
approved by the Human Gamete, Embryo, and Stem Cell Research Committee
(institutional review board) at the University of California, San Francisco.
Two sets of samples included twins: GW20_31 and GW20_34; GW22 and GW22T.

<section>Single-cell RNA sequencing capture and processing</section>
<p>
Brain dissections were performed under a stereoscope with regards to major
sulci to identify cortical regions. Of note, all dissections were performed by
the same individual (T.J.N.) to enable reproducibility and comparison between
samples. Tissue was incubated in 4 ml of papain/DNAse solution (Worthington)
for 20 min at 37 °C, after which it was carefully triturated with a glass
pipette, filtered through a 40-µm cell strainer and washed with HBSS. The GW22
and GW25 samples were additionally passed through an ovomucoid gradient
(Worthington) in order to minimize myelin debris in the captures. The final
single-cell suspension was loaded onto a droplet-based library prep platform
Chromium (10X Genomics) according to the manufacturer’s instructions. Version 2
was used for all samples except for GW19_2, GW16, and GW18_2 for which version
3 chemistry was used. cDNA libraries were quantified using an Agilent 2100
Bioanalyzer and sequenced with an Illumina NovaSeq S4.

<section>Quality control and filtering</section>
<p>
We filtered cells using highly stringent quality control (QC) metrics. In
brief, we discarded potential doublets using the R package scrublet29 for each
individual capture lane, then required at least 750 genes per cell and removed
cells with high levels (>10%) of mitochondrial gene content. These strict
metrics for quality control preserved no more than 40% of cells for downstream
analysis, and re-analysis of the data for specific brain structures or cell
types may benefit from less stringent QC for additional discovery. Our goal was
to obtain clean populations with a high validation rate for a better
understanding of arealization signatures. The resulting ~700,000 cells passing
all thresholds were used in downstream analyses.

<section>Clustering strategy</section>
<p>
We used a recursive clustering workflow to understand the cell types present in
our dataset. In order to minimize potential batch effects and to increase
detection sensitivity of potential rare cell populations, we performed
Louvain–Jaccard clustering on each individual sample first. After initial cell
type classification, we sub-clustered all the cells belonging to a cell type to
generate the most granular cell subtypes possible. We then correlated subtypes
between individuals based upon the gene scores in all marker genes to bridge
any batch effects, and iteratively combined clusters across all individuals and
cell types. For this study, we combined the clusters within a single cell type
across all individuals once, and again with all clusters from all individuals
and cell types, resulting in two iterative combinations. The annotations at
each step are preserved in the supplementary tables to enable reconstruction at
any point in the pipeline.
"""

# Note that all of these identifiers can also be a list of values.
# e.g. you could write 
# pmid = ["123123", "23423423"]
# All identifiers and URLS can contain a optional description after a space

# URL to pre-print
#biorxiv_url = "https://www.biorxiv.org/content/123/123.full Strangelove et al."
# URL to paper fulltext
paper_url = "https://www.nature.com/articles/s41586-021-03910-8 Bhaduri et al. Nature. 2021."
# URL to some other dataset related website, e.g. the hosting lab's own viewer
other_url= "https://data.nemoarchive.org/biccn/grant/u01_devhu/kriegstein/transcriptome/scell/10x_v2/human/processed/counts/ Raw Count Data in NeMO"
# DOI
#doi="xxx"
#

# PMID of publication
pmid = "34616070"
# GEO Series accession, usually starts with GSE
# geo_series = "GSE25097"
# dbGaP accession, usually starts with phs.
# dbgap = "phs000424.v7.p2"
# arrayexpress accession
# arrayexpress = "xxx"
# ENA project accession
# ena_project = "ENAP12341"
# SRA accession
# sra_study = "xxxx"
# NBCI Bioproject acccession
# bioproject = "xxxx"
# Others:
# cirm_dataset= "xxxx"
# ega_study="xxxx"
#
# supplemental files can be a raw expression matrix, Seurat or Scanpy files or anything else, like protocols
# supplFiles = [
# { "file" : "seurat3.rds", "label" : "Seurat3 RDS"},
# { "file" : "scanpy.h5ad", "label" : "Scanpy h5ad"},
# ]
# You can add a file with the original raw data, if needed. It gets copied over and added to the Downloads tab, with a note
# rawMatrixFile= "raw10XFile.mtz.zip"
# rawMatrixNote= "Original 10X output file"

submitter = "Aparna Bhaduri"
version = 1
submission_date = "2021-10-15"
lab = "Arnold Kriegstein Lab"
institution= "UCSF"
#
# Any other information you want to show on the dataset info page
#custom = {"sample barcode": "1231-HH11" }
#
