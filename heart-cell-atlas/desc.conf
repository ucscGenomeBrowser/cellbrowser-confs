title = "Cells of the adult human heart"

# a thumbnail image of some nice image representing your dataset, sometimes it's figure 1, sometimes 
# the journal cover, or just a screenshot of the t-SNE plot. If the file is bigger than 400px,
# optimize the image size to something smaller that can load progressively with this Unix command:
# convert myImage.png -sampling-factor 4:2:0 -strip -quality 85 -interlace JPEG -colorspace sRGB -resize 400^ thumb.jpg

#image = "thumb.jpg"

# abstract of paper or dataset summary text
abstract = """
<p>
From <a href="https://www.nature.com/articles/s41586-020-2797-4"
target="_blank">Litviňuková et al</a>:
<p>
Cardiovascular disease is the leading cause of death worldwide. Advanced
insights into disease mechanisms and therapeutic strategies require a deeper
understanding of the molecular processes involved in the healthy heart.
Knowledge of the full repertoire of cardiac cells and their gene expression
profiles is a fundamental first step in this endeavour. Here, using
state-of-the-art analyses of large-scale single-cell and single-nucleus
transcriptomes, we characterize six anatomical adult heart regions. Our results
highlight the cellular heterogeneity of cardiomyocytes, pericytes and
fibroblasts, and reveal distinct atrial and ventricular subsets of cells with
diverse developmental origins and specialized properties. We define the
complexity of the cardiac vasculature and its changes along the arterio-venous
axis. In the immune compartment, we identify cardiac-resident macrophages with
inflammatory and protective transcriptional signatures. Furthermore, analyses
of cell-to-cell interactions highlight different networks of macrophages,
fibroblasts and cardiomyocytes between atria and ventricles that are distinct
from those of skeletal muscle. Our human cardiac cell atlas improves our
understanding of the human heart and provides a valuable reference for future
studies.
"""

# methods: please describe roughly what the samples are and how you processed them computationally
methods = """
<section>Chromium 10X library preparation</section>
<p>
Single cells and nuclei were manually counted by Trypan blue exclusion or
automatically using a Countess II (Life Technologies) using at least two
separate counts. Cell or nuclei suspension was adjusted to 400–1,000 cells per
microlitre and loaded on the Chromium Controller (10X Genomics) with a targeted
cell or nuclei recovery of 4,000–10,000 per reaction. 3′ gene expression
libraries were prepared according to the manufacturer’s instructions of the v2
or v3 Chromium Single Cell Reagent Kits (10X Genomics). Quality control of cDNA
and final libraries was done using Bioanalyzer High Sensitivity DNA Analysis
(Agilent) or 4200 TapeStation System (Agilent). Libraries were sequenced using
HiSeq 4000 (Illumina) at Wellcome Sanger Institute, and NextSeq 500 (Illumina)
at Harvard Medical School with a minimum depth of 20,000–30,000 read pairs per
cell or nucleus (Supplementary Table 22).

<section>Count data processing</section>
<p>
After mapping, samples from each data source (single nuclei, single cell and
CD45+ cell) were grouped into individual AnnData objects by concatenating the
raw_feature_bc_matrix_h5.h5 and adding the appropriate metadata information.
For each data source object, the mean of unique molecular identifiers (UMIs)
(n_counts) was calculated and used as a threshold for empty droplets.

<section>Doublet detection</section>
<p>
After removal of empty droplets, we applied scrublet to assign a doublet
score (scrublet_score) to each cell. These cells were clustered and visualized
using the UMAP method. In addition, each cell was processed for doublet
detection using a percolation method to allow for improved detection of
doublets.

<section>Cell quality control and filtering</section>
<p>
Each data source was processed and annotated separately to account for
source-specific quality differences. These metrics are included as covariates
for further processing. Total cells and CD45+ cells were filtered for counts
(500 &lt; n_counts &lt;15,000), genes (200 < n_genes), mitochondrial genes
(percent_mito &lt;20%), ribosomal genes (percent_ribo <20%) and scrublet score
(scrublet_score &lt;0.3). Single nuclei were filtered for counts (500 < n_counts
&lt;15,000), genes (300 &lt; n_genes &lt;6,000), mitochondrial genes (percent_mito &lt;5%),
ribosomal genes (percent_ribo &lt;5%) and scrublet score (scrublet_score <0.3).
The same filtering thresholds were applied to the skeletal muscle dataset.
<p>
Scanpy toolkit 1.5 in Python v.3.7 was used to perform downstream analyses,
including normalization (normalize_per_cell: counts_per_cell_after = 10,000),
log transformation (log1p), variable gene detection (highly_variable_genes),
regressing out unwanted sources of variation (regress_out: n_counts and
percent_mito), data feature scaling (scale: max_value = 10) and PCA (pca: using
highly variable genes) as previously described.
"""

# Note that all of these identifiers can also be a list of values.
# e.g. you could write 
# pmid = ["123123", "23423423"]
# All identifiers and URLS can contain a optional description after a space

# URL to pre-print
#biorxiv = "https://www.biorxiv.org/content/123/123.full Strangelove et al."
# URL to paper fulltext
paper_url = "https://www.nature.com/articles/s41586-020-2797-4 Litviňuková et al. 2020. Nature."
# URL to some other dataset related website, e.g. the hosting lab's own viewer
other_url= "http://www.heartcellatlas.org/ Heart Cell Atlas"
# DOI
#doi="xxx"
#

# PMID of publication
pmid = "32971526"
# GEO Series accession, usually starts with GSE
# geo_series = "GSE25097"
# dbGaP accession, usually starts with phs.
# dbgap = "phs000424.v7.p2"
# arrayexpress accession
# arrayexpress = "xxx"
# ENA project accession
ena_project = "ERP123138"
# SRA accession
# sra_study = "xxxx"
# NBCI Bioproject acccession
# bioproject = "xxxx"
# Others:
# cirm_dataset= "xxxx"
# ega_study="xxxx"
#
# supplemental files can be a raw expression matrix, Seurat or Scanpy files or anything else, like protocols
# supplFiles = [
# { "file" : "seurat3.rds", "label" : "Seurat3 RDS"},
# { "file" : "scanpy.h5ad", "label" : "Scanpy h5ad"},
# ]
# You can add a file with the original raw data, if needed. It gets copied over and added to the Downloads tab, with a note
# rawMatrixFile= "raw10XFile.mtz.zip"
# rawMatrixNote= "Original 10X output file"

#submitter = "John Doe"
version = 1
submission_date = "2021-02-08"
lab = ["J. G. Seidman", "Christine E. Seidman", "Michela Noseda", "Norbert Hubner", "Sarah A. Teichmann"]
institution= ["Harvard Medical School","Imperial College London","Max Delbrück Center for Molecular Medicine in the Helmholtz Association (MDC)","University of Cambridge"]
#body_part = "brain"
#
# Any other information you want to show on the dataset info page
#custom = {"sample barcode": "1231-HH11" }
#
